---
title: '**GoldPredict: Inflation & Market Impact Insights**'
author: "Johannes Werner"
date: "`r format(Sys.Date(), '%d %B, %Y')`"
output:
  pdf_document:
    df_print: kable
    number_sections: true
    toc: true
    fig_caption: true
  word_document:
    toc: true
  html_document: default
subtitle: 'HarvardX Data Science Professional Certificate: PH125.9x Capstone 2'
fontsize: 11pt
header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{caption}
  - \usepackage{float}
  - \usepackage{enumitem}
  - \usepackage[bottom]{footmisc}
  - \usepackage{hyperref}
  - \setlength{\abovecaptionskip}{4pt}
  - \setlength{\belowcaptionskip}{0pt}
  - \setlist[itemize]{itemsep=0pt}
  - \setlist[enumerate]{itemsep=0pt}
include-before: '`\newpage{}`{=latex}'
urlcolor: blue
bibliography: references.bib
---

```{r setup, include=FALSE}
# knitr global chunk options
# Sets default figure dimensions, alignment, and positioning for knitr output
knitr::opts_chunk$set(
  fig.width = 4.5,
  fig.height = 3,
  fig.align = 'center',
  fig.pos = "H"
)

# Custom kable function
# Defines a reusable function to style tables with scaling and positioning
if(!require(kableExtra)) install.packages("kableExtra")
library(kableExtra)

my_kable <- function(x, caption = NULL) {
  knitr::kable(x, 
               format = "latex",
               booktabs = TRUE,
               caption = caption,
               linesep = "") %>%
    kable_styling(
      latex_options = c("scale_down", "hold_position"),
      font_size = 9,
      position = "center"
    )
}

# Load and install ggplot2 library if needed
if(!require(ggplot2)) install.packages("ggplot2")
# Imports ggplot2 for data visualization
library(ggplot2)

# Set custom ggplot2 theme
# Applies a minimal theme with adjusted font sizes and margins
theme_set(
  theme_minimal() +
    theme(
      plot.title = element_text(size = rel(0.9)),
      axis.title = element_text(size = rel(0.8)),
      axis.text = element_text(size = rel(0.7)),
      legend.title = element_text(size = rel(0.8)),
      plot.margin = unit(c(2,2,2,2), "mm"),
      plot.caption = element_text(size = rel(0.6), hjust = 1)
    )
)
```

\newpage

```{r data_preparation, eval=TRUE, include=FALSE, cache=TRUE}
# Install and load quantmod package if not already installed
if(!require(quantmod)) install.packages("quantmod")
library(quantmod)

# Fetch gold prices (GC=F) from Yahoo Finance starting from 1974-01-01
getSymbols("GC=F", src = "yahoo", from = "1974-01-01", to = "2025-03-13")
gold_prices <- `GC=F`
# Remove the original symbol object to clean up workspace
rm(`GC=F`)

# Fetch S&P 500 data (^GSPC) from Yahoo Finance starting from 2000-01-01
getSymbols("^GSPC", src = "yahoo", from = "2000-01-01", to = "2025-03-13")
sp500_data <- `GSPC`
# Remove the original symbol object to clean up workspace
rm(`GSPC`)

# Load CPI data from FRED (Federal Reserve Economic Data)
getSymbols("CPIAUCSL", src = "FRED", from = "2000-01-01", to = "2025-03-13")
cpi_data <- CPIAUCSL
# Calculate year-over-year (YoY) inflation rate (12 months lag
inflation_rate_yoy <- 100 * (cpi_data / lag(cpi_data, 12) - 1)
# Clean up by removing temporary CPI objects
rm(cpi_data, CPIAUCSL)


# Install and load necessary libraries for data manipulation and plotting
if(!require(dplyr)) install.packages("dplyr")
library(dplyr)
if(!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)

# Convert gold prices to a data frame with Date and average GoldPrice
gold_prices_df <- data.frame(Date = index(gold_prices), GoldPrice = coredata(gold_prices))
gold_prices_df <- gold_prices_df %>%
  mutate(GoldPrice = (GoldPrice.GC.F.High + GoldPrice.GC.F.Low) / 2) %>%
  select(Date, GoldPrice)

# Convert S&P 500 data to a data frame with Date and average SP500Price
sp500_data_df <- data.frame(Date = index(sp500_data), SP500 = coredata(sp500_data))
sp500_data_df <- sp500_data_df %>%
  mutate(SP500Price = (SP500.GSPC.High + SP500.GSPC.Low) / 2) %>%
  select(Date, SP500Price)

# Convert inflation rate to a data frame and rename the inflation column
inflation_rate_yoy_df <- data.frame(Date = index(inflation_rate_yoy), InflationRate = coredata(inflation_rate_yoy))
inflation_rate_yoy_df <- inflation_rate_yoy_df %>%
  rename(InflationIndex = CPIAUCSL)

# Remove original time series objects to free up memory
rm(gold_prices,inflation_rate_yoy,sp500_data)

# Merge all data frames by Date using left joins
merged_data <- sp500_data_df %>%
  left_join(gold_prices_df, by = "Date") %>%
  left_join(inflation_rate_yoy_df, by = "Date")

# Install and load zoo package for handling NA interpolation
if(!require(zoo)) install.packages("zoo")
library(zoo)

# Linearly interpolate NA values in the time series
merged_data$GoldPrice <- na.approx(merged_data$GoldPrice, x = merged_data$Date, na.rm = FALSE)
merged_data$SP500Price <- na.approx(merged_data$SP500Price, x = merged_data$Date, na.rm = FALSE)
merged_data$InflationIndex <- na.approx(merged_data$InflationIndex, x = merged_data$Date, na.rm = FALSE)

# Fill remaining NAs at the start or end using last observation carried forward/backward
merged_data$InflationIndex <- na.locf(merged_data$InflationIndex, fromLast = FALSE, na.rm = FALSE)
merged_data$InflationIndex <- na.locf(merged_data$InflationIndex, fromLast = TRUE, na.rm = FALSE)
merged_data$GoldPrice <- na.locf(merged_data$GoldPrice, fromLast = FALSE, na.rm = FALSE)
merged_data$GoldPrice <- na.locf(merged_data$GoldPrice, fromLast = TRUE, na.rm = FALSE)
```


# Introduction

The project, GoldPredict: Inflation & Market Impact Insights analyzes and attempts to predict gold prices with the use of inflation rates and market performance by the S&P 500 index. Gold is usually called a safe-haven asset, in uncertain market conditions and its price is influenced by various factors. Understanding the gold price relationship can possibly provide helpful insights for investors.

The dataset includes historical data from the beginning of 2000 to March 2025, including:

\begin{itemize}
\item \textbf{Gold Prices: }Daily gold prices (GC=F) sourced from Yahoo Finance, as the average of the daily high and low.
\item \textbf{S\&P 500 Index: }Daily S\&P 500 index values (\textasciicircum GSPC) sourced from Yahoo Finance, also as the average of the daily high and low.
\item \textbf{Inflation Rates: }Year-over-year inflation rates derived from the Consumer Price Index (CPIAUCSL) sourced from the Federal Reserve Economic Data (FRED) and calculated as the change in percentage over the previous 12 months.
\end{itemize}
\textbf{Sources: }[@yahoo], [@federal].

The goal of this project is to predict gold prices by modeling the relationship between gold prices, inflation rates, and the S&P 500 index, using machine learning techniques. The project is divided into the following steps:

\begin{itemize}
\item \textbf{Data Exploration: }Analyze and visualize the dataset to get an overview and possibly identify patterns and relationships between gold prices, inflation, and market performance.
\item \textbf{Modeling: }Apply linear regression and random forest models and evaluate their performance using model metrics respectively on a prediction of the gold price the beginning of 2025.
\item \textbf{Evaluation: }Apply linear regression and random forest models to predict gold prices, evaluating their performance on random time periods.
\end{itemize}

The report was created using R Markdown in RStudio including the use of the R programming language for statistical computing and data analysis.

\newpage

# Data Exploration

This section explores the dataset. The structure of the data is shown and the relationships between gold prices, S&P 500 prices, and inflation rates are visualized. The dataset contains `r format(nrow(merged_data),big.mark=",",scientific=F)` rows of information and covers the period from January 3, 2000, to March 12, 2025.

\textbf{Remark:} Due to the fact that inflation data is originally available only monthly, a linear interpolation was applied during data preparation to also get daily values. This ensures consistent data with the gold and S&P 500 data. The interpolation helps to align the dataset for the machine learning models.

The data structure is presented through a summary of key statistics created with the summary command and shows the range of values for each variable (see Table 1).

```{r look_in_data, eval=TRUE, cache=TRUE, include=TRUE, echo=FALSE}
# Show summary of merged_data
summary(merged_data) %>%
  my_kable(caption = "Summary of data metrics")
```

In Table 2 exemplarily, the row structure from rows 900 to 905 is illustrated. The format and content of the dataset, including dates and corresponding gold prices, S&P 500 prices, and inflation rates can be seen.

```{r row_structure, eval=TRUE, cache=TRUE, include=TRUE, echo=FALSE}
# Display rows 900 to 905 of merged_data to show an example of the row structure
merged_data[900:905, ]%>%
  my_kable(caption = "Row structure example from line 900 to 905")
```

In Figure 1 an overview of the raw data for gold prices, S&P 500 prices, and inflation rates, plotted separately, can be seen to gain insight into their individual trends over time.

```{r all_data_raw, eval=TRUE, echo=FALSE, cache=TRUE, include=TRUE, fig.width=6.6, fig.height=4, fig.cap="Gold, SP 500 and Inflation chart from 2000 till now"}
# Install and load gridExtra package for arranging multiple plots
if(!require(gridExtra)) install.packages("gridExtra")
library(gridExtra)

# Arrange multiple ggplot charts in a single column layout
grid.arrange(
  # Plot gold prices over time with a line connecting the data points
  ggplot(merged_data, aes(x = Date)) +
    geom_line(aes(y = GoldPrice, color = "Gold")) +
    scale_y_continuous(labels = function(x) format(x, scientific = FALSE,big.mark=",")) +
    scale_color_manual(values = c("Gold" = "gold", "S&P 500" = "blue", "Inflation" = "red")) +
    labs(x = "Date", y = "Price [$]", color = "") +
    theme(aspect.ratio = 1/3, legend.title = element_blank()),

   # Plot S&P 500 prices over time with a line connecting the data points
  ggplot(merged_data, aes(x = Date)) +
    geom_line(aes(y = SP500Price, color = "S&P 500"), na.rm = TRUE) +
    scale_y_continuous(labels = function(x) format(x, scientific = FALSE,big.mark=",")) +
    scale_color_manual(values = c("Gold" = "gold", "S&P 500" = "blue", "Inflation" = "red")) +
    labs(x = "Date", y = "Price [$]", color = "") +
    theme(aspect.ratio = 1/3, legend.title = element_blank()),

  # Plot inflation index over time with a line connecting the data points
  ggplot(merged_data, aes(x = Date)) +
    geom_line(aes(y = InflationIndex, color = "Inflation"), na.rm = TRUE) +
    scale_y_continuous(labels = function(x) format(x, scientific = FALSE,big.mark=",")) +
    scale_color_manual(values = c("Gold" = "gold", "S&P 500" = "blue", "Inflation" = "red")) +
    labs(x = "Date", y = "Value [%]", color = "") +
    theme(aspect.ratio = 1/3, legend.title = element_blank()),
  
  # Specify single-column layout for the three plots
  ncol = 1
)
```

Figure 2 displays the normalized trends of gold prices, S&P 500 prices, and inflation rates from the start of the dataset (2000). Gold price and the S&P 500 are scaled to 100 at the beginning (January 3, 2000) to be able to make a relative comparison. In this period, until March 2025, gold performed best, by showing the greatest relative growth and it was able to preserve value over the crises between 2000 and 2010.

```{r normed_data_2000, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE,fig.width=6.6, warning=FALSE, message=FALSE, fig.cap="Comparison of Normalized Gold Prices, SP 500, and Inflation Rate from 2000 onwards"}
# Normalize data to the year 2000
# Normalize gold prices (first value = 100)
gold_prices_df$NormalizedGoldPrice <- (gold_prices_df$GoldPrice / gold_prices_df$GoldPrice[1]) * 100

# Normalize S&P 500 data (first value = 100)
sp500_data_df$NormalizedSP500 <- (sp500_data_df$SP500 / sp500_data_df$SP500[1]) * 100

# Load scales package for secondary axis functionality
if(!require(scales)) install.packages("scales")
library(scales)

# Define a function to filter and plot data starting from a specific date
normalized_plot <- function(start_date) {
  # Filter data based on the specified start date
  filtered_gold <- gold_prices_df[gold_prices_df$Date >= start_date, ]
  filtered_sp500 <- sp500_data_df[sp500_data_df$Date >= start_date, ]
  filtered_inflation <- inflation_rate_yoy_df[inflation_rate_yoy_df$Date >= start_date, ]
  
  # Create the plot
  ggplot() +
    # Plot normalized gold prices (left y-axis)
    geom_line(data = filtered_gold, aes(x = Date, y = NormalizedGoldPrice, color = "Gold Price"), size = 1) +
    
    # Plot normalized S&P 500 (left y-axis)
    geom_line(data = filtered_sp500, aes(x = Date, y = NormalizedSP500, color = "S&P 500"), size = 1) +
    
    # Plot inflation rate (right y-axis, scaled for visibility)
    geom_line(data = filtered_inflation, aes(x = Date, y = InflationIndex * 100, color = "Inflation Rate"), size = 0.5, linetype = "dashed") +
    
    # Define primary and secondary y-axes
    scale_y_continuous(
      name = "Normalized Value [%]",
      limits = c(-200, 1000),
      sec.axis = sec_axis(~ . / 100, name = "Inflation Rate [%]") # Rescale inflation rate for the secondary axis
    ) +
    
    # Set colors and legend order
    scale_color_manual(
      values = c("Gold Price" = "gold", "S&P 500" = "blue", "Inflation Rate" = "red"),
      breaks = c("Gold Price", "S&P 500", "Inflation Rate") # Specify legend order
    ) +
    
     # Add labels and customize theme
    labs(x = "Date",
         color = "Legend") +
    theme(legend.title = element_blank())
}

# Call the plot function with the start date of 2000-01-01
normalized_plot(as.Date("2000-01-01"))
```

In another diagram (Figure 3) the trend starts at 2010. In this case the values are scaled again to 100 but based on the beginning of 2010. In this timeframe, the S&P 500 outperformed gold, which reflects the market's growth and economic recovery.

```{r normed_data_2010, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE,fig.width=6.6, warning=FALSE, message=FALSE, fig.cap="Comparison of Normalized Gold Prices, SP 500, and Inflation Rate from 2010 onwards"}
# Normalize gold prices to 2010-01-04 (first value = 100)
gold_prices_df$NormalizedGoldPrice <- (gold_prices_df$GoldPrice / gold_prices_df$GoldPrice[gold_prices_df$Date == as.Date("2010-01-04")]) * 100

# Normalize S&P 500 to 2010-01-04 (first value = 100)
sp500_data_df$NormalizedSP500 <- (sp500_data_df$SP500 / sp500_data_df$SP500[gold_prices_df$Date == as.Date("2010-01-04")]) * 100

library(scales)

# Function to plot normalized data from a specific start date
normalized_plot <- function(start_date) {
  filtered_gold <- gold_prices_df[gold_prices_df$Date >= start_date, ]
  filtered_sp500 <- sp500_data_df[sp500_data_df$Date >= start_date, ]
  filtered_inflation <- inflation_rate_yoy_df[inflation_rate_yoy_df$Date >= start_date, ]
  
  ggplot() +
    geom_line(data = filtered_gold, aes(x = Date, y = NormalizedGoldPrice, color = "Gold Price"), size = 1) +
    geom_line(data = filtered_sp500, aes(x = Date, y = NormalizedSP500, color = "S&P 500"), size = 1) +
    geom_line(data = filtered_inflation, aes(x = Date, y = InflationIndex * 100, color = "Inflation Rate"), size = 0.5, linetype = "dashed") + 
    scale_y_continuous(
      name = "Normalized Value [%]",
      limits = c(-200, 1000),
      sec.axis = sec_axis(~ . / 100, name = "Inflation Rate [%]") # Rückskalierung der Inflationsrate
    ) +
    scale_color_manual(
      values = c("Gold Price" = "gold", "S&P 500" = "blue", "Inflation Rate" = "red"),
      breaks = c("Gold Price", "S&P 500", "Inflation Rate") # Reihenfolge der Legende
    ) +
    
    labs(x = "Date",
         color = "Legend")
}

# Plot data starting from 2010-01-01
normalized_plot(as.Date("2010-01-01"))
```

So, depending on the chosen timeframe, the gold price relative to the S&P 500 can over long periods develop differently.

\newpage

# Methods

In this chapter, the mathematical methods and techniques used for evaluating the gold price prediction models are described. The process is outlined step-by-step, performance metrics are introduced and the model approaches are explained.

## Methodology Overview

The analysis and modeling were carried out as follows:

\begin{itemize}
 \item Fit of linear model (LM) - check correlation matrix and model residuals to assess its suitability.
 \item Fit a random forest (RF) model – check performance metrics and variable importance.
 \item Train the RF model on test data and predict gold prices for the beginning of 2025 – evaluate its performance.
 \item Train the RF model with cross-validation and compare the results to the model without cross-validation.
 \item Check the model performance of the RF model on 12 random dates in the data between 2010 and 2025.
 \item Check the model performance of the LM model on 12 random dates in the data between 2010 and 2025.
 \item Compare the two models using the performance metrics.
\end{itemize}

## Performance metric: RMSE

To be able to objectively evaluate the predictive accuracy of the models, two performance metrics were used: Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE). These metrics are useful for small test sets (small number of prediction days) as they focus on absolute and relative errors and are not variance-based like R-squared, which possibly could mislead with limited data.

\textbf{Root Mean Squared Error (RMSE)}: Measures the average squared deviation between predicted and actual values. It is a measure of the average deviation between predicted and actual ratings and defined as [@irizarry_introduction_2019, Ch. 33.7.3]:

$$
\text{RMSE} = \sqrt{\frac{1}{N} \sum_{i=1}^{N} \left( \hat{y}_{i} - y_{i} \right)^2}
$$ 
Where:

\begin{itemize}
 \item $y_{i}$ is the actual gold price
 \item $\hat{y}_{i}$ is the predicted gold price
 \item $N$ is the total number of observations
\end{itemize}

\textbf{Mean Absolute Percentage Error (MAPE):} Measures the average absolute error as a percentage of the actual value, which leads to a relative measure of prediction accuracy [@mape]:
$$
\text{MAPE} = \frac{1}{N} \sum_{i=1}^{N} \left| \frac{\hat{y}_i - y_i}{y_i} \right| \times 100
$$ 
\textbf{Definitions:} Same as above.

## Linear model

Linear regression model assumes a linear relationship between the dependent variable (gold price) and the independent ones (S\&P 500 price and inflation rate). The model is defined in the following formula [@irizarry_introduction_2019, Ch. 31]:

$$
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon
$$ 
Where:
\begin{itemize}
  \item $Y$ is the dependent variable representing the gold price in USD
  \item $X_1$ is the S\&P 500 index value in USD
  \item $X_2$ is the year-over-year inflation rate in percentage
  \item $\beta_0$ is the intercept of the model
  \item $\beta_1$ and $\beta_2$ are the coefficients for the predictors $SP500Price$ and $InflationIndex$
  \item $\epsilon$ is the error term
\end{itemize}

The model coefficients ($\beta_0$, $\beta_1$, $\beta_2$) are approximated by using the sum of least squares method. Residual diagnostics were performed to check the performance and usefulness of the model.


## Random forest model

Random Forest is an ensemble learning method which constructs decision trees and combines their predictions to get high accuracy and reduced overfitting. Each tree is built on a data sample. At each decision or split a random subset of predictors is taken into account to improve the generalization [@ibm_2021] [@irizarry_introduction_2019, Ch. 35.2].
In this project, the random forest model predicts gold prices (GoldPrice) while its predictors are S&P 500 prices (SP500Price) and inflation rates (InflationIndex). The model has 500 trees ($ntree=500$) while the variable importance was assessed to understand the contribution of the individual predictors. The final prediction is the average of the predictions from all trees. This makes the model robust to noisy datasets and nonlinear relationships.


## Cross validation

Cross validation is a method to assess the generalization performance of a model by checking it on multiple data subsets. In K-fold cross validation, the data is divided into $k$ folds. The model is trained on $k-1$ folds and the performance is tested on the remaining fold. This procedure is carried out $k$ times, so that every "fold" is tested once. The performance metric is averaged across all folds to estimate the model's performance regarding predictions on unseen data [@irizarry_introduction_2019, Ch. 29].
In this project, 10-fold cross-validation ($k=10$) was applied to the random forest model to evaluate the performance and to compare it with a trained model without cross validation. This helps to ensure that the performance of the model is not interpreted as too optimistic due to overfitting on the training data.


\newpage

# Results

This chapter shows the findings from the actual analysis and modeling of the gold price with the presented linear regression and random forest models. The results include correlation analysis, model diagnostics, variable importance, predictive performance across different time periods, and comparisons of the models. At the end of the section, the model results are interpreted.


## Correlation Analysis

The correlation plot shows the relationship between gold prices, S&P 500 prices, and inflation rates. It provides insights regarding their interdependencies. In the plot Pearson correlation coefficients are used, shown by numbers, where values range from -1 to 1 (perfect negative to perfect positive correlation) [@correlation_pearson]. High positive correlation (e.g., 0.8) between gold prices and S&P 500 prices suggests that as the S&P 500 increases, the gold price tends to rise too, while a negative correlation value might indicate an inverse relationship.

```{r corrplot, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.cap="Correlation plot of Gold Prices, SP 500, and Inflation rate"}
# Install and load corrplot package if not already installed
if(!require(corrplot)) install.packages("corrplot")
library(corrplot)

# Calculate correlation matrix for selected columns
correlation_matrix <- cor(merged_data[, c("GoldPrice", "SP500Price", "InflationIndex")])

# Visualize the correlation matrix with numbers in the upper triangle
corrplot(correlation_matrix, method = "number", type = "upper",number.cex = 0.8,tl.cex = 0.8,cl.offset = 0.1,cl.cex = 0.4)  

```

## Linear Regression Diagnostics

The diagnostic plots for the linear model assess if its assumptions — like linearity, normality of residuals, and homoscedasticity — are met. The four plots show: (1) Residuals vs Fitted, to check for nonlinearity; (2) Normal Q-Q, to verify normality of residuals; (3) Scale-Location, to assess homoscedasticity; (4) Residuals vs Leverage, to detect outliers affecting the model.

Deviations in these plots, such as a curved pattern in Residuals vs. Fitted or points far away from the Q-Q line, indicate violations from the assumptions [@understanding_diagnostics].

```{r lm_model_residuals, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE,fig.width=6.6,fig.height=5 , warning=FALSE, message=FALSE, fig.cap="Check of linear regression model"}
# Create a linear regression model with GoldPrice as dependent variable
lm_model <- lm(GoldPrice ~ SP500Price + InflationIndex, data = merged_data)

# Display results 
#summary(lm_model)

# Install and load ggfortify for diagnostic plots if not already installed
if(!require(ggfortify)) install.packages("ggfortify")
library(ggfortify)

# Generate diagnostic plots in a 2x2 grid
autoplot(lm_model, which = c(1, 2, 3, 5), ncol = 2, nrow = 2)+
  geom_point(shape = 1, alpha = 0.2, size =0.05)
```

\subsection*{Interpretation of the diagnostics:}
\vspace{-0.5cm}
[@understanding_diagnostics]
\vspace{0.1cm}

\textbf{1. Residuals vs Fitted}

This plot shows a nonlinear pattern, where the residuals are arbitrarily spread around the blue graph. This indicates that the linear model does not accurately capture the relationships in the data. Instead of a random scatter, high positive residuals can be seen at lower fitted values, gradually decreasing. It seems that nonlinear terms in the model might be needed.

\textbf{2. Normal Q-Q}

The Q-Q plot shows the deviations from normality. The middle section follows the reference line relatively well, but there are significant differences at both ends (especially at the upper one). This gives the hint that the residuals have heavier tails than a normal distribution. This could have an effect on the validity of the statistics from the model.

\textbf{3. Scale-Location}

This plot shows heteroscedasticity issues. The spread of the standardized residuals varies across the fitted values, while it seems to be wider at lower fitted values and comes closer at higher values. The curved blue line confirms this. Equal variance (homoscedasticity) is an important assumption of linear regression. That was violated here.

\textbf{4. Residuals vs Leverage}

The pattern here shows potentially influential observations. Most points lie in the range of lower leverage values but some could have an undue influence on the regression coefficients.

However, none seem to exceed Cook's distance, which suggests that no single observation is critically altering the results.

\vspace{0.3cm}

With these superficial interpretations, overall, these diagnostics suggest that the linear model has several issues that should be addressed: nonlinearity, non-normality of residuals, heteroscedasticity, and potentially influential observations. Alternative model approaches are advised.

This meets the expectation that gold prices are, of course not linear dependent on S&P 500 prices and inflation rates.
Because of that, the development of the linear model stopped at this point.
Nevertheless, this can be seen as a demonstration on how to possibly do this in a systematic way with more suitable data.

```{r rf_prep1, eval=TRUE, include=FALSE, cache=TRUE}
# Install and load randomForest package if not already installed
if(!require(randomForest)) install.packages("randomForest")
library(randomForest)

# Set seed for reproducibility
set.seed(123)
```

## Random Forest Model Metrics

The random forest model is created by the following code:

```{r rf_prep2, eval=TRUE, include=TRUE, cache=TRUE}
# Create Random Forest model with 500 trees
rf_model <- randomForest(GoldPrice ~ SP500Price + InflationIndex,
                         data = merged_data,
                         importance = TRUE,
                         ntree = 500)
```                        
     
The model’s performance metrics provide an initial impression of how it fits the entire dataset.
\vspace{-0.3cm}
\begin{itemize}
  \item \textbf{Mean of squared residuals:} `r format(rf_model$mse[length(rf_model$mse)], big.mark = ",", scientific = F, digits = 5)`
  \item \textbf{Percentage of variance explained (\% Var explained):} `r format(rf_model$rsq[length(rf_model$rsq)] * 100, big.mark = ",", scientific = F, digits = 4)`\%
  \item \textbf{Number of trees:} `r rf_model$ntree`
  \item \textbf{Number of variables tried at each split:} `r rf_model$mtry`
\end{itemize}
\vspace{-0.3cm}
The metrics indicate that the model explains a relatively high portion of the variance in the gold prices. However, further evaluation is needed to determine whether the mean of squared residuals is acceptable and with that if the model can make good predictions.


## Variable Importance in Random Forest

The variable importance plot in Figure 6 for the random forest model shows the contribution of each predictor (S&P 500 price and inflation rate) to the predictions of the model. Two metrics are shown: the increase in mean squared error (%IncMSE) if a variable is permuted, and the increase in node purity (IncNodePurity) which is based on the variance reduction at each split. The higher the values, the greater the importance. [@rpubs_RandomForest] E.g., if S&P 500 price has a high %IncMSE, exchanging its values significantly reduces the accuracy, which means that it is a key variable of the gold price prediction in the model.

```{r rf_var_importance, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE, fig.width=5,fig.height=3, warning=FALSE, message=FALSE, fig.cap="Importance of the variables"}
# Visualize variable importance from the Random Forest model
par(cex.axis = 0.8) 
par(cex.lab = 0.8)  
varImpPlot(rf_model)
```

```{r test_train_data, eval=TRUE, include=FALSE, cache=TRUE}
# Training data: up to end of 2024
train_data <- merged_data[merged_data$Date < as.Date("2025-01-01"), ]

# Test data: from 2025 onwards
test_data <- merged_data[merged_data$Date >= as.Date("2025-01-01"), ]
```

```{r train_rf_w/o_cv, eval=TRUE, include=FALSE, cache=TRUE}
# Train Random Forest model on training data without cross-validation
set.seed(123)
rf_model_train <- randomForest(GoldPrice ~ SP500Price + InflationIndex,
                               data = train_data,
                               importance = TRUE,
                               ntree = 500)

# Display model results
print(rf_model_train)


# Generate predictions for test data
test_data$Predicted_GoldPrice <- predict(rf_model_train, test_data)

# Check the first few predictions
head(test_data[, c("Date", "GoldPrice", "Predicted_GoldPrice")])
```

```{r train_rf_w_cv, eval=TRUE, include=FALSE, cache=TRUE}
# Install and load caret package if not already installed
if(!require(caret)) install.packages("caret")
library(caret)

# Train Random Forest model on training data with 10-fold cross-validation
set.seed(123)
# Define 10-fold cross-validation method
train_control <- trainControl(method = "cv", number = 10)


rf_model_train_cv <- randomForest(GoldPrice ~ SP500Price + InflationIndex,
                               data = train_data,
                               method = "rf",
                               trControl = train_control,
                               ntree = 500)

# Display model results
print(rf_model_train)


# Generate predictions for test data
test_data$Predicted_GoldPrice2 <- predict(rf_model_train_cv, test_data)

# Check the first few predictions
head(test_data[, c("Date", "GoldPrice", "Predicted_GoldPrice","Predicted_GoldPrice2")])
```

##  Random Forest Predictions for 2025

The plot in Figure 7 compares the actual gold prices with predictions from the random forest model with and without cross validation. The test period starts in January 2025 and tests the models performance until March 13th. The orange dashed line "Predicted Gold Price (cv)" represents predictions using 10-fold cross validation. The green dashed line shows the predictions without cross validation. As there are no significant differences visible, this suggests that cross validation does not significantly improve the model's performance.

```{r rf_results_2025, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE, fig.width=5,fig.height=3, warning=FALSE, message=FALSE, fig.cap="Plot of rf predictions",fig.height=3}
library(ggplot2)

# Plot actual vs. predicted gold prices
ggplot(test_data, aes(x = Date)) +
  geom_line(aes(y = GoldPrice, color = "Actual Gold Price")) +
  geom_line(aes(y = Predicted_GoldPrice, color = "Predicted Gold Price"), linetype = "dashed") +
  geom_line(aes(y = Predicted_GoldPrice2, color = "Predicted Gold Price (cv)"), linetype = "dashed") +
  labs(title = "Actual vs. Predicted Gold Prices (Test Data)",
       x = "Date",
       y = "Gold Price (USD)",
       color = "Legend") +
  scale_color_manual(values = c("Actual Gold Price" = "gold", "Predicted Gold Price" = "darkgreen","Predicted Gold Price (cv)"="orange"))
```

The first interpretation is that the model performs relatively well for up to two weeks, but afterwards the prediction accuracy seems to disappear. In the next chapter, a series of time intervals is analyzed to evaluate the performance over different periods.


## Random Forest Predictions at Random Time Points

To evaluate the performance across different market conditions, 12 random start dates for prediction between 2010 and 2025 were selected.
Only short term is predicted (10 days each) because of the observations in chapter 4.5. The random start dates start at 2010 so that there is at least 10 years before the actual prediction to train the model.
The start dates are generated with the following code:

```{r random_start_dates, eval=TRUE, include=TRUE, cache=TRUE}
set.seed(17) # For reproducibility

# Define date range
start_date <- as.Date("2010-01-01")
end_date <- as.Date("2025-02-28")

# Generate 12 random dates
random_dates <- sample(seq(start_date, end_date, by = "day"), 12)

# Sort the dates for better readability
random_dates <- sort(random_dates)
```

The randomly selected dates are as follows:
\vspace{-0.5cm}
```{r random_start_dates2, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE}
# Show random dates
random_dates
```

With these start dates, the process for evaluating the model involves several steps, which are looped for every date. The code for these steps, the iteration loops, the diagrams and the performance metrics is relatively complicated and long. The basic framework for this process was initially set up manually.

However, the final development and refinement of the code loop was completed with the help of AI tools (cf. Usage of Artificial Intelligence).

The steps in the code are listed below:
\vspace{-0.5cm}
\begin{itemize}
  \item Filter training data up to the start date to ensure the model learns only from historical data.
  \item Identify the last training data point to anchor the predictions.  
  \item Define a 10-day test period immediately following the last training date.  
  \item Combine the last training point with the test data for continuity.  
  \item Train the random forest model on the training data.  
  \item Generate predictions for the test period and correct them by shifting the first predicted value to the last actual training value to ensure the starting condition.  
  \item Calculate the performance metrics (RMSE, MAPE) to assess prediction accuracy.  
  \item Store the predictions and metrics, and create a plot for each start date showing actual vs. predicted gold prices.  
  \item Combine all plots into a grid for comparison.
\end{itemize}

The predictions are stored in an extra dataframe with the following structure:
\vspace{-0.5cm}
```{r rf_testing_w/o_cv, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}
# Install and load packages if not already installed
if(!require(patchwork)) install.packages("patchwork")
if(!require(cowplot)) install.packages("cowplot")
if(!require(Metrics)) install.packages("Metrics")
library(ggplot2)
library(gridExtra)
library(Metrics)
library(dplyr)
library(randomForest)
library(patchwork)
library(cowplot)

# Initialize lists to store plots, accuracy metrics, and prediction data
plot_list_rf <- list()
accuracy_list_rf <- list()
prediction_data_list_rf <- list()

# Loop through the randomly generated start dates
for (start_date in random_dates) {
  # Filter training data up to the start date
  train_data <- merged_data %>%
    filter(Date <= start_date)
  
  # Identify the last training point (most recent date in training data)
  last_train_date <- max(train_data$Date)
  last_train_point <- merged_data %>%
    filter(Date == last_train_date)
  
  # Define test data: 10 days after the last training date
  test_start_date <- last_train_date + 1
  test_end_date <- test_start_date + 10
  test_data <- merged_data %>%
    filter(Date >= test_start_date & Date <= test_end_date)
  
  # Combine the last training point with the test data for plotting purposes
  combined_data <- rbind(last_train_point, test_data)
  
  # Skip iteration if no test data is available
  if (nrow(test_data) == 0) next
  
  # Train a Random Forest model using the training data
  rf_model_temp <- randomForest(GoldPrice ~ SP500Price + InflationIndex,
                                data = train_data,
                                importance = TRUE,
                                ntree = 500)
  
  # Make predictions and apply correction to align with the last training point
  combined_data$Predicted_GoldPrice <- predict(rf_model_temp, combined_data)
  last_train_gold_price <- last_train_point$GoldPrice
  predicted_start_value <- combined_data$Predicted_GoldPrice[1]
  correction_factor <- last_train_gold_price - predicted_start_value
  combined_data$Predicted_GoldPrice <- combined_data$Predicted_GoldPrice + correction_factor
  
  # Update the test data with corrected predictions
  test_data$Predicted_GoldPrice <- combined_data$Predicted_GoldPrice[match(test_data$Date, combined_data$Date)]
  
  # Calculate accuracy metrics (RMSE and MAPE) for the test data
  rmse_value <- rmse(test_data$GoldPrice, test_data$Predicted_GoldPrice)
  mape_value <- mean(abs((test_data$GoldPrice - test_data$Predicted_GoldPrice) / test_data$GoldPrice)) * 100
  
  # Store accuracy metrics in a list
  accuracy_list_rf[[as.character(start_date)]] <- data.frame(
    StartDate = as.Date(start_date),
    RMSE = rmse_value,
    MAPE = mape_value
  )
  
  # Save prediction data for each start date in a list
  prediction_data_list_rf[[as.character(start_date)]] <- combined_data %>%
    select(Date, GoldPrice, Predicted_GoldPrice) %>%
    mutate(StartDate = as.Date(start_date))
  
  # Create a plot comparing actual and predicted gold prices
  p <- ggplot(combined_data, aes(x = Date)) +
    geom_line(aes(y = GoldPrice, color = "Actual Gold Price")) +
    geom_line(aes(y = Predicted_GoldPrice, color = "Predicted Gold Price"), linetype = "dashed") +
    labs(title = paste("RF - Start Date:", format(as.Date(start_date), "%m/%d/%Y")),
         x = "Date",
         y = "Gold Price (USD)",
         color = "") + # Entfernt den Legendentitel
    scale_color_manual(values = c("Actual Gold Price" = "gold", "Predicted Gold Price" = "darkgreen")) +
    scale_x_date(date_labels = "%m/%d") + # Amerikanisches Datum ohne Jahr auf der x-Achse
    scale_y_continuous(labels = comma) + # Tausender-Trennzeichen für y-Achse
    theme_minimal() +
    theme(
      plot.title = element_text(size = rel(0.7)),
      axis.title = element_text(size = rel(0.7)),
      axis.text.x = element_text(size = rel(0.7)),
      axis.text.y = element_text(size = rel(0.7)),
      legend.position = "none" # Entfernt die Legende aus den einzelnen Plots
    )
  
  # Add plot to the list of plots
  plot_list_rf[[as.character(start_date)]] <- p
}

# Combine all accuracy results into a single dataframe
accuracy_results_rf <- do.call(rbind, accuracy_list_rf)

# Combine all prediction data into a single dataframe for further analysis or visualization
all_prediction_data_rf <- do.call(rbind, prediction_data_list_rf)

# Display the first few rows of the prediction data
#print("Prediction Data (Random Forest) - Head:")
print(head(all_prediction_data_rf))

```

The performance metrics are also stored. This is shown in the following table:
\vspace{-0.5cm}
```{r rf_testing_w/o_cv2, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}
# Display accuracy results for the Random Forest model
#print("Accuracy Results (Random Forest):")
print(accuracy_results_rf)
```

The resulting grid plot in Figure 8 displays the random forest model predictions for each of the 12 random start dates. This allows a visual assessment of the performance across different time periods.

```{r rf_testing_w/o_cv3, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE, fig.width=6.6,fig.height=8.8, warning=FALSE, message=FALSE, fig.cap="Plot of rf predictions for random start dates"}
# Combine all plots into a grid with a shared legend at the bottom
final_plot <- patchwork::wrap_plots(plot_list_rf, ncol = 3) + 
              patchwork::plot_layout(guides = 'collect') & 
              theme(legend.position="bottom")

# Display the final combined plot
final_plot
```

The plot shows more or less random predictions, where no clear or consistent pattern can be seen.
This suggests that the model, despite promising metrics during testing, is not suitable for gold price prediction with random starting points. Consequently, it also seems that it should not be used for making predictions about gold price trends for the future.


## Linear Regression Predictions at Random Time Points

Similarly, the performance of the linear regression model is evaluated in the same way as the random forest model to compare their effectiveness.
Although the linear regression model was already excluded in testing due to its low performance, it is included here again for comparison purposes because doing this is just a simple code modification.

The resulting grid plot of the predictions for the linear regression model can be seen in Figure 9.

```{r lm_testing, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE, fig.width=6.6,fig.height=8.8, warning=FALSE, message=FALSE, fig.cap="Plot of lm predictions for random start dates"}
# load packages
library(ggplot2)
library(gridExtra)
library(Metrics)
library(dplyr)
library(randomForest)
library(patchwork)
library(cowplot)

# Initialize lists to store plots, accuracy metrics, and prediction data
plot_list_lm <- list()
accuracy_list_lm <- list()
prediction_data_list_lm <- list()

# Loop through the randomly generated start dates
for (start_date in random_dates) {
  # Filter training data up to the start date
  train_data <- merged_data %>%
    filter(Date <= start_date)
  
  # Identify the last training point (most recent date in training data)
  last_train_date <- max(train_data$Date)
  last_train_point <- merged_data %>%
    filter(Date == last_train_date)
  
  # Define test data: 10 days after the last training date
  test_start_date <- last_train_date + 1
  test_end_date <- test_start_date + 10
  test_data <- merged_data %>%
    filter(Date >= test_start_date & Date <= test_end_date)
  
  # Combine the last training point with the test data for plotting purposes
  combined_data <- rbind(last_train_point, test_data)
  
  # Skip iteration if no test data is availabled
  if (nrow(test_data) == 0) next
  
  # Train a Linear Regression model using the training data
  lm_model_temp <- lm(GoldPrice ~ SP500Price + InflationIndex, data = train_data)
  
  # Make predictions and apply correction to align with the last training point
  combined_data$Predicted_GoldPrice <- predict(lm_model_temp, newdata = combined_data)
  last_train_gold_price <- last_train_point$GoldPrice
  predicted_start_value <- combined_data$Predicted_GoldPrice[1]
  correction_factor <- last_train_gold_price - predicted_start_value
  combined_data$Predicted_GoldPrice <- combined_data$Predicted_GoldPrice + correction_factor
  
  # Update the test data with corrected predictions
  test_data$Predicted_GoldPrice <- combined_data$Predicted_GoldPrice[match(test_data$Date, combined_data$Date)]
  
  # Calculate accuracy metrics (RMSE and MAPE) for the test data
  rmse_value <- rmse(test_data$GoldPrice, test_data$Predicted_GoldPrice)
  mape_value <- mean(abs((test_data$GoldPrice - test_data$Predicted_GoldPrice) / test_data$GoldPrice)) * 100
  
  # Store accuracy metrics in a list
  accuracy_list_lm[[as.character(start_date)]] <- data.frame(
    StartDate = as.Date(start_date),
    RMSE = rmse_value,
    MAPE = mape_value
  )
  
  # Save prediction data for each start date in a list
  prediction_data_list_lm[[as.character(start_date)]] <- combined_data %>%
    select(Date, GoldPrice, Predicted_GoldPrice) %>%
    mutate(StartDate = as.Date(start_date))
  
  # Create a plot comparing actual and predicted gold prices
  p <- ggplot(combined_data, aes(x = Date)) +
    geom_line(aes(y = GoldPrice, color = "Actual Gold Price")) +
    geom_line(aes(y = Predicted_GoldPrice, color = "Predicted Gold Price"), linetype = "dashed") +
    labs(title = paste("LM - Start Date:", format(as.Date(start_date), "%m/%d/%Y")),
         x = "Date",
         y = "Gold Price (USD)",
         color = "") + # Entfernt den Legendentitel
    scale_color_manual(values = c("Actual Gold Price" = "gold", "Predicted Gold Price" = "purple")) +
    scale_x_date(date_labels = "%m/%d") + # Amerikanisches Datum ohne Jahr auf der x-Achse
    scale_y_continuous(labels = comma) + # Tausender-Trennzeichen für y-Achse
    theme_minimal() +
    theme(
      plot.title = element_text(size = rel(0.7)),
      axis.title = element_text(size = rel(0.7)),
      axis.text.x = element_text(size = rel(0.7)),
      axis.text.y = element_text(size = rel(0.7)),
      legend.position = "none" # Entfernt die Legende aus den einzelnen Plots
    )
  
  # Add plot to the list of plots
  plot_list_lm[[as.character(start_date)]] <- p
}

# Combine all accuracy results into a single dataframe
accuracy_results_lm <- do.call(rbind, accuracy_list_lm)

# Combine all prediction data into a single dataframe for further analysis or visualization
all_prediction_data_lm <- do.call(rbind, prediction_data_list_lm)

# Display accuracy results for the lm model
#print("Accuracy Results (Linear Regression):")
#print(accuracy_results_lm)

# Display the first few rows of the prediction data
#print("Prediction Data (Linear Regression) - Head:")
#print(head(all_prediction_data_lm))

# Combine all plots into a grid with a shared legend at the bottom
final_plot <- patchwork::wrap_plots(plot_list_lm, ncol = 3) + 
              patchwork::plot_layout(guides = 'collect') & 
              theme(legend.position="bottom")

# Display the final combined plot
final_plot
```

The model aligns relatively well with the actual trends in around 7 out of 12 cases. However, there are time frames where the prediction deviates very much from the observed prices. Overall, the linear regression model demonstrates surprisingly a better prediction performance than the random forest model. But also here, no consistent pattern can be found across the predictions.

The lack of a clear pattern may also not be reliable for predicting future gold price trends, although it seems to be an improvement over the random forest approach.


## Model Comparison

The comparison plot of model accuracy over time contrasts the performance of the linear regression and random forest models using RMSE and MAPE across the 12 random start dates, highlighting differences in predictive accuracy.

The comparison plot in Figure 10 compares the 2 applied models by the defined metrics RMSE and MAPE across the 12 starting points. It shows the differences in the predictive accuracy. Here the visual impression from the chapter before is confirmed. The linear regression model seems to perform better than the random forest model.

```{r evaluation, eval=TRUE, include=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE,fig.height=5.4, fig.cap="Model evaluation metrics"}
# Combine accuracy metrics for comparison across models
accuracy_results_combined <- rbind(
  data.frame(Model = "Linear Regression", accuracy_results_lm),
  data.frame(Model = "Random Forest", accuracy_results_rf)
)

library(ggplot2)
library(patchwork)

# Visualization of metrics over time
# Create RMSE plot comparing models
RMSE <- ggplot(accuracy_results_combined, aes(x = StartDate, y = RMSE, color = Model)) +
  geom_point() + geom_line() +
  scale_color_manual(values = c("Linear Regression" = "purple", "Random Forest" = "darkgreen")) +
  labs(title = "Comparison of Model Accuracy Over Time",
       x = "Start Date",
       y = "RMSE (USD)")

# Create MAPE plot comparing models
MAPE <- ggplot(accuracy_results_combined, aes(x = StartDate, y = MAPE, color = Model)) +
  geom_point() + geom_line() +
  scale_color_manual(values = c("Linear Regression" = "purple", "Random Forest" = "darkgreen")) +
  labs(title = "MAPE Comparison", x = "Start Date", y = "MAPE (%)")

# Combine RMSE and MAPE plots into a single layout with shared legend at the bottom
RMSE / MAPE + 
  plot_layout(guides = 'collect') & 
  theme(legend.position = "bottom")
```


## Interpretation of Results

The random forest model seemed to be robust in its performance metrics during testing. However, it performed worse than expected when applied to random prediction starting points. Cross validation virtually had no effect on the results. This could be due to the stability of the random forest algorithm in itself.

The linear regression model shows better prediction performance with the actual gold prices in some cases, but both models are not really good for a reliable prediction. This suggests that there are additional factors missing. This could be other financial indices or political and economic influences. These may somehow be implemented in the model to improve the predictive accuracy.


\newpage

# Conclusion

In this project, GoldPredict: Inflation & Market Impact Insights, the relationship between gold prices, inflation rates, and the S&P 500 index was analyzed.  Predictive models using linear regression and random forest techniques were developed. The models provided insights into short-term gold price movements, but several limitations and areas for improvement were identified.

\textbf{Key Findings}

The random forest model was robust in capturing the nonlinear relationships - but performed in the end worse than expected in the shown scenarios. The linear regression model showed better performance with the actual trends, but not in every time frame or market condition. Both models struggled to make good predictions at random starting points.

The gold price movement is related to Inflation rates and S&P 500 prices, but the impact is varying in different time periods. Other factors, such as geopolitical events or governmental interventions, can have a significant effect on the gold prices, which is not included in the analysis.

\textbf{Limitations}

The dataset includes only inflation rates and S&P 500 prices as predictors. Including broader indices like the MSCI World or macroeconomic indicators could possibly lead to better results. Additionally, political and regulatory interventions have not been considered, which may limit the prediction accuracy during intervention or event phases.

Furthermore, the suitability of the prediction models was not assessed before, which may also have contributed to their limited performance.

\textbf{Learnings and Future Work}

Despite the limitations, a lot of learnings came out of the analysis. Evaluating the model's suitability for the given data beforehand is important. Future efforts in predicting gold prices should focus on identifying patterns in the price movement directly before the prediction periods in such ways that in specific phases the models might perform better. This could lead to being able to find conditions, market phases, or time frames, under which the models align better with the actual trends.

To improve accuracy and applicability:
\vspace{-0.5cm}
\begin{itemize}
  \item Implement additional predictors like interest rates, forex rates, or geopolitical indices.
  \item Investigate how market conditions directly before the predictions have an influence on the model's performance.
\end{itemize}
\vspace{-0.5cm}
By addressing this, future studies can possibly have enhanced predictive abilities and can provide better insights into gold price movements.


\newpage

# Usage of Artificial Intelligence {.unnumbered}

\textbf{\large Perplexity AI – R code assistance}

\begin{itemize}
  \item \textbf{Website:} \url{https://www.perplexity.ai}
  \item \textbf{Used in:} Results section (ggplot syntax correction, model testing)
  \item \textbf{Purpose:} Syntax correction and debugging support for ggplot visualizations and assistance in creating the code for data preparation, random dates testing and start value correction for random forest and lm model.
\end{itemize}
\vspace{15pt}

\textbf{\large Perplexity AI – Content crosscheck and writing tips}

\begin{itemize}
  \item \textbf{Website:} \url{https://www.perplexity.ai}
  \item \textbf{Used in:} Introduction and Conclusion sections
  \item \textbf{Purpose:} Crosschecking content accuracy and logical structure; providing suggestions for improvements regarding clarity, precision, and scientific writing style.
\end{itemize}
\vspace{15pt}

\textbf{\large AI Grammar Checker | Sapling}

\begin{itemize}
  \item \textbf{Website:} \url{https://sapling.ai/grammar-check}
  \item \textbf{Used in:} Entire report
  \item \textbf{Purpose:} Grammar and spelling correction.
\end{itemize}
\vspace{15pt}

\textbf{\large Grok from X - R code commenting}

\begin{itemize}
  \item \textbf{Website:} \url{https://x.com}
  \item \textbf{Used in:} R Code
  \item \textbf{Purpose:} Assisting in generating code comments.
\end{itemize}

\newpage

# References
